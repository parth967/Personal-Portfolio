# Parth Patel
**Senior Data Engineer**

üìû 519-778-5965 | ‚úâÔ∏è pparth967@gmail.com | üîó [LinkedIn](https://www.linkedin.com/in/parth-patel-72a92611a/) | üåê Portfolio

## Objective

Results-driven Senior Data Engineer with proven expertise in ETL/ELT frameworks, data integration, and analytics across cloud and on-premises platforms. Skilled in Azure, Databricks, Synapse, and Power BI with strong proficiency in SQL, PySpark, and Python. Adept at designing scalable data pipelines, optimizing transformations for performance and cost, and enabling trusted, governed data solutions. Collaborative team player committed to automation, metadata-driven design, and delivering business-ready insights.

## Experience

### TD Bank ‚Äì IT Data Specialist (Senior Data Engineer)
**Toronto, Jan 2022 ‚Äì Present**
- Designed and implemented a metadata-driven Azure Data Integration Framework streamlining ingestion, processing, and decision-making workflows
- Built scalable ETL pipelines in Databricks & PySpark, integrating ADLS ‚Üí Synapse with performance tuning and cost optimization
- Developed Power BI dashboards with advanced DAX and Power Query, integrating multiple enterprise data sources
- Implemented data quality, lineage, and governance controls for trusted insights and compliance
- Partnered with architecture teams to define technology patterns for data ingestion, transformation, and monitoring
- Leveraged Datadog and native Azure monitoring to ensure reliability, SLA adherence, and system optimization

### Next Pathway Inc. ‚Äì Software Developer (Data Engineer)
**Toronto, Jul 2021 ‚Äì Jan 2022**
- Delivered cloud migration and ETL modernization as part of the SHIFT‚Ñ¢ Roadmap, ensuring seamless client adoption
- Converted ETL/ELT pipelines (DataStage ‚Üí PySpark) using automated code generation tools and manual optimization
- Developed automation scripts & APIs in Python & Java, using OpenAPI, YAML, XML, and Connexion
- Conducted performance tuning, unit, and functional testing to ensure pipeline reliability
- Collaborated with analytics teams to deliver insights using Tableau & Power BI

### Earthbound AI ‚Äì Data Platform & API Developer
**Remote, Jan 2020 ‚Äì Jul 2021**
- Built a geospatial imagery API (Fast API + PostGIS + Rasterio/GDAL) supporting STAC-compliant search, XYZ tiles, and on-demand image processing
- Designed and managed an AWS S3 data lake with encryption (KMS), VPC endpoints, and IAM least-privilege policies
- Automated ingestion of Sentinel/Landsat data with Airflow (MWAA), event-driven pipelines (S3 ‚Üí SNS/SQS), and retry mechanisms
- Implemented COG preparation & QA (thumbnails, overviews, footprints) with ECS/Lambda jobs before STAC publishing
- Tuned CloudFront caching & S3 delivery to reduce latency and egress costs
- Maintained Terraform IaC for S3, IAM, MWAA, and API Gateway with GitHub Actions CI/CD

## Education

**B.E. Information Technology** ‚Äì Gujarat Technological University, India

**Postgraduate Certificate, IT Business Analysis** ‚Äì Conestoga College, Kitchener, Canada

## Core Skills

### Programming & Scripting
- Python, Java, SQL, Shell, Bash

### Big Data & Analytics
- Apache Spark, Hadoop, PySpark, Databricks, Power BI (DAX, Power Query), Snowflake

### ETL/ELT Tools
- Talend, Apache NiFi, ADF, custom frameworks

### Cloud Platforms
- Azure (Synapse, ADLS, Databricks), AWS (S3, Kinesis, Lambda, MWAA)

### Streaming & Orchestration
- Apache Kafka, Airflow, AWS Step Functions

### Data Modeling
- ERD, Dimensional Modeling, Metadata-driven Design

### DevOps & Automation
- Docker, Kubernetes, Terraform, Git, Jenkins, CI/CD